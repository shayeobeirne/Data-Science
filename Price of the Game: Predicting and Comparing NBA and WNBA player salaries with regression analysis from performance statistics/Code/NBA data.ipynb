{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebde6a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa38ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NBA Positions\n",
    "URL = \"https://www.cbssports.com/nba/stats/player/scoring/nba/regular/all-pos/qualifiers/?sortcol=gp&sortdir=descending&page=1\"\n",
    "page = requests.get(URL)\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "name = []\n",
    "positions = []\n",
    "positions_binary = []\n",
    "\n",
    "results = soup.find_all(\"span\", class_ = \"CellPlayerName--long\")\n",
    "for line in results:\n",
    "    player_name = line.find('a')\n",
    "    player_position = (line.find('span', class_ = \"CellPlayerName-position\")).text\n",
    "    player_position = player_position.replace(\"\\n                            \", \"\")\n",
    "    player_position = player_position.replace(\"\\n                        \", \"\")\n",
    "    name.append(player_name.text)\n",
    "    positions.append(player_position)\n",
    "\n",
    "URL = URL.replace(\"1\", \"\")\n",
    "\n",
    "for i in range(2,13):\n",
    "    URL = URL.replace(str(i - 1), \"\")\n",
    "    URL = URL + str(i)\n",
    "    page = requests.get(URL)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "    results = soup.find_all(\"span\", class_ = \"CellPlayerName--long\")\n",
    "    for line in results:\n",
    "        player_name = line.find('a')\n",
    "        player_position = (line.find('span', class_ = \"CellPlayerName-position\")).text\n",
    "        player_position = player_position.replace(\"\\n                            \", \"\")\n",
    "        player_position = player_position.replace(\"\\n                        \", \"\")\n",
    "        name.append(player_name.text)\n",
    "        positions.append(player_position)\n",
    "\n",
    "# POSSIBLE POSITIONS: C, PF, SF, PG, SG\n",
    "\n",
    "#INTERACTED REGRESSION VARIABLE\n",
    "#Also we should find the total points scored among players or avg ppg and group by position to see the highest scoring positions\n",
    "for i in positions:\n",
    "    if (i == \"SG\" or i == \"PG\" or i == \"SF\"):\n",
    "        positions_binary.append(1)\n",
    "    else:\n",
    "        positions_binary.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d0a882",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NBA Performance Stats\n",
    "URL = \"https://www.cbssports.com/nba/stats/player/scoring/nba/regular/all-pos/qualifiers/?sortcol=gp&sortdir=descending&page=1\"\n",
    "page = requests.get(URL)\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "data = []\n",
    "usable_data = []\n",
    "\n",
    "starts  = []\n",
    "games   = []\n",
    "minutes = []\n",
    "mpg     = []\n",
    "points  = []\n",
    "ppg     = []\n",
    "fgper   = []\n",
    "\n",
    "results = soup.find_all(\"td\", class_ = \"TableBase-bodyTd\")\n",
    "for number in results:\n",
    "    data.append(number.text)\n",
    "\n",
    "URL = URL.replace(\"1\", \"\")\n",
    "\n",
    "for i in range(2,13):\n",
    "    URL = URL.replace(str(i - 1), \"\")\n",
    "    URL = URL + str(i)\n",
    "    page = requests.get(URL)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "    results = soup.find_all(\"td\", class_ = \"TableBase-bodyTd\")\n",
    "    for number in results:\n",
    "        data.append(number.text) \n",
    "\n",
    "#USABLE DATA\n",
    "for i in range(len(data)):\n",
    "    if ((i != 0) and (i%14 != 0)):\n",
    "        stat = data[i].replace(\"\\n                    \", \"\")\n",
    "        stat = stat.replace(\"                 \", \"\")\n",
    "        if (\"â€”\" in data[i]):\n",
    "            stat = 0\n",
    "        usable_data.append(float(stat))\n",
    "\n",
    "#START PERCENTAGE\n",
    "for i in range(int(len(usable_data)/13)):\n",
    "    gp = usable_data[i*13]\n",
    "    gs = usable_data[(i*13) + 1]\n",
    "    prop = gs/gp\n",
    "    starts.append(prop)\n",
    "\n",
    "#GAMES PLAYED\n",
    "for i in range(int(len(usable_data)/13)):\n",
    "    games.append(int(usable_data[i*13]))\n",
    "\n",
    "#MINUTES PER GAME\n",
    "for i in range(int(len(usable_data)/13)):\n",
    "    mpg.append(float(usable_data[(i*13) + 2]))\n",
    "\n",
    "#TOTAL MINUTES\n",
    "for i in range(int(len(usable_data)/13)):\n",
    "    minutes_pg = usable_data[(i*13) + 2]\n",
    "    games_played = usable_data[i*13]\n",
    "    minutes.append(float(minutes_pg*games_played))\n",
    "\n",
    "#POINTS PER GAME\n",
    "for i in range(int(len(usable_data)/13)):\n",
    "    ppg.append(float(usable_data[(i*13) + 3]))\n",
    "\n",
    "#TOTAL POINTS\n",
    "for i in range(int(len(usable_data)/13)):\n",
    "    points_pg = usable_data[(i*13) + 3]\n",
    "    games_played = usable_data[i*13]\n",
    "    points.append(int(points_pg*games_played))\n",
    "\n",
    "#FIELD GOAL %\n",
    "for i in range(int(len(usable_data)/13)):\n",
    "    fgper.append(float(usable_data[(i*13) + 6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9eeeb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NBA Salaries\n",
    "URL = \"http://www.espn.com/nba/salaries\"\n",
    "page = requests.get(URL)\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "results = soup.find_all(\"div\", class_ = \"mod-content\")\n",
    "table = soup.find_all(\"table\", class_ = \"tablehead\")\n",
    "\n",
    "data_even = soup.find_all(\"tr\", class_ = \"evenrow\")\n",
    "data_odd = soup.find_all(\"tr\", class_ = \"oddrow\")\n",
    "\n",
    "names_even = []\n",
    "names_odd  = []\n",
    "\n",
    "salaries_even = []\n",
    "salaries_odd  = []\n",
    "\n",
    "#These will be the final columns to be added to the csv\n",
    "names = []\n",
    "salaries = []\n",
    "\n",
    "for line in data_even:\n",
    "    player_name = line.find('a')\n",
    "    names_even.append(player_name.text)\n",
    "    player_salary = line.find('td', style=\"text-align:right;\")\n",
    "    player_salary = (str(player_salary.text)).replace(\"$\",\"\")\n",
    "    player_salary = (player_salary).replace(\",\",\"\")\n",
    "    salaries_even.append(player_salary)\n",
    "for line in data_odd:\n",
    "    player_name = line.find('a')\n",
    "    names_odd.append(player_name.text)\n",
    "    player_salary = line.find('td', style=\"text-align:right;\")\n",
    "    player_salary = (str(player_salary.text)).replace(\"$\",\"\")\n",
    "    player_salary = (player_salary).replace(\",\",\"\")\n",
    "    salaries_odd.append(player_salary)\n",
    "for i in range(len(names_even)):\n",
    "    names.append(names_odd[i])\n",
    "    names.append(names_even[i])\n",
    "    salaries.append(salaries_odd[i])\n",
    "    salaries.append(salaries_even[i])\n",
    "\n",
    "for i in range(2,16):\n",
    "    if i != 0:\n",
    "        URL = \"http://www.espn.com/nba/salaries/_\"\n",
    "        URL = URL + \"/page/\" + str(i)\n",
    "\n",
    "        page = requests.get(URL)\n",
    "        soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "        data_even = soup.find_all(\"tr\", class_ = \"evenrow\")\n",
    "        data_odd = soup.find_all(\"tr\", class_ = \"oddrow\")\n",
    "\n",
    "        names_even = []\n",
    "        names_odd  = []\n",
    "\n",
    "        salaries_even = []\n",
    "        salaries_odd  = []\n",
    "\n",
    "    for line in data_even:\n",
    "        player_name = line.find('a')\n",
    "        names_even.append(player_name.text)\n",
    "        player_salary = line.find('td', style=\"text-align:right;\")\n",
    "        player_salary = (str(player_salary.text)).replace(\"$\",\"\")\n",
    "        player_salary = (player_salary).replace(\",\",\"\")\n",
    "        salaries_even.append(player_salary)\n",
    "    for line in data_odd:\n",
    "        player_name = line.find('a')\n",
    "        names_odd.append(player_name.text)\n",
    "        player_salary = line.find('td', style=\"text-align:right;\")\n",
    "        player_salary = (str(player_salary.text)).replace(\"$\",\"\")\n",
    "        player_salary = (player_salary).replace(\",\",\"\")\n",
    "        salaries_odd.append(player_salary)\n",
    "    for i in range(len(names_even)):\n",
    "        names.append(names_odd[i])\n",
    "        names.append(names_even[i])\n",
    "        salaries.append(salaries_odd[i])\n",
    "        salaries.append(salaries_even[i])\n",
    "df = pd.read_csv('NBA_data_salaries.csv')\n",
    "df[\"Names\"] = names\n",
    "df[\"Salary\"] = salaries\n",
    "df.to_csv('NBA_data_salaries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf253a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing to see if positions have meaningful effect on salary\n",
    "positions_test1 = []\n",
    "positions_test2 = []\n",
    "for i in range(len(positions)):\n",
    "    test = []\n",
    "    test.append(positions[i])\n",
    "    test.append(ppg[i])\n",
    "    positions_test1.append(test)\n",
    "\n",
    "for i in range(len(positions)):\n",
    "    test = []\n",
    "    test.append(positions[i])\n",
    "    test.append(points[i])\n",
    "    positions_test2.append(test)\n",
    "\n",
    "SF_val = []\n",
    "C_val = []\n",
    "PG_val = []\n",
    "SG_val = []\n",
    "PF_val = []\n",
    "\n",
    "for i in range(len(positions_test1)):\n",
    "    if positions_test1[i][0] == 'SF':\n",
    "        SF_val.append(positions_test1[i][1])\n",
    "    elif positions_test1[i][0] == 'C':\n",
    "        C_val.append(positions_test1[i][1])\n",
    "    elif positions_test1[i][0] == 'PG':\n",
    "        PG_val.append(positions_test1[i][1])\n",
    "    elif positions_test1[i][0] == 'SG':\n",
    "        SG_val.append(positions_test1[i][1])\n",
    "    elif positions_test1[i][0] == 'PF':\n",
    "        PF_val.append(positions_test1[i][1])\n",
    "\n",
    "SF_val1 = []\n",
    "C_val1 = []\n",
    "PG_val1 = []\n",
    "SG_val1 = []\n",
    "PF_val1 = []\n",
    "\n",
    "for i in range(len(positions_test2)):\n",
    "    if positions_test1[i][0] == 'SF':\n",
    "        SF_val1.append(positions_test2[i][1])\n",
    "    elif positions_test1[i][0] == 'C':\n",
    "        C_val1.append(positions_test2[i][1])\n",
    "    elif positions_test1[i][0] == 'PG':\n",
    "        PG_val1.append(positions_test2[i][1])\n",
    "    elif positions_test1[i][0] == 'SG':\n",
    "        SG_val1.append(positions_test2[i][1])\n",
    "    elif positions_test1[i][0] == 'PF':\n",
    "        PF_val1.append(positions_test2[i][1])\n",
    "\n",
    "print(\"PPG grouped by position:          \",  stats.f_oneway(SF_val, C_val, PG_val, SG_val, PF_val))\n",
    "print(\"Total Points grouped by position: \", stats.f_oneway(SF_val1, C_val1, PG_val1, SG_val1, PF_val1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768f5126",
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries_sorted = []\n",
    "\n",
    "for i in range(len(name)):\n",
    "    salaries_sorted.append(0)\n",
    "\n",
    "for i in range(len(name)):\n",
    "    if name[i] in names:\n",
    "        salaries_sorted[i] = salaries[names.index(name[i])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cbbc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('NBA_data_perf.csv')\n",
    "df[\"Name\"] = name\n",
    "df[\"Position\"] = positions\n",
    "df[\"Starts\"] = starts\n",
    "df[\"Total Games\"] = games\n",
    "df[\"Total Mins\"] = minutes\n",
    "df[\"Total Points\"] = points\n",
    "df[\"MPG\"] = mpg\n",
    "df[\"PPG\"] = ppg\n",
    "df[\"FG %\"] = fgper\n",
    "df[\"Salaries\"] = salaries_sorted\n",
    "df.to_csv('NBA_data_perf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54109c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_names = []\n",
    "missing_salaries = []\n",
    "\n",
    "for i in range(len(names)):\n",
    "    if names[i] not in name:\n",
    "        missing_names.append(names[i])\n",
    "        missing_salaries.append(salaries[i])\n",
    "        \n",
    "df = pd.read_csv('missing.csv')\n",
    "df[\"Name\"] = missing_names\n",
    "df[\"Salary\"] = missing_salaries\n",
    "df.to_csv('missing.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cea823",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('nba-player-stats-final.csv')\n",
    "sal_names = df['Name']\n",
    "sal_salaries = df['Salaries']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1ffa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://www.basketball-reference.com/contracts/players.html\"\n",
    "page = requests.get(URL)\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "names1 = []\n",
    "names2 = []\n",
    "missing_names = []\n",
    "missing_salaries = []\n",
    "salaries_found = []\n",
    "\n",
    "for i in range(len(sal_names)):\n",
    "    if sal_salaries[i] == 0:\n",
    "        names2.append(sal_names[i])\n",
    "        \n",
    "results = soup.find_all(attrs = {\"data-stat\": \"y1\"})\n",
    "for i in results:\n",
    "    if i.text != \"2021-22\":\n",
    "        if \"$\" in i.text:\n",
    "            salary = (i.text).replace(\"$\",\"\")\n",
    "            salary = salary.replace(\",\", \"\")\n",
    "            missing_salaries.append(int(salary))\n",
    "        else:\n",
    "            missing_salaries.append(0)\n",
    "\n",
    "line = soup.find_all(\"tr\")\n",
    "\n",
    "\n",
    "for i in line:\n",
    "    name = i.find('a')\n",
    "    if \"href\" in str(name):\n",
    "        if name.text in names2:\n",
    "            missing_names.append(name.text)\n",
    "\n",
    "results[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f538b7e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
